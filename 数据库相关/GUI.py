import sys
import os
import json
import traceback
import mysql.connector
from mysql.connector import errorcode

from PyQt5.QtWidgets import (QApplication, QWidget, QVBoxLayout, QHBoxLayout, QPushButton,
                             QFileDialog, QLabel, QTabWidget, QTextEdit, QComboBox,
                             QLineEdit, QMessageBox, QProgressDialog, QGroupBox, QFormLayout,
                             QSizePolicy)  # Added QSizePolicy
from PyQt5.QtCore import Qt, QThread, pyqtSignal
from PyQt5.QtGui import QFont, QIcon  # Optional for better styling

# --- æ•°æ®åº“é…ç½® ---
DB_CONFIG = {
    'host': 'localhost',
    'user': 'root',
    'password': '123456',  # !!! è¯·æ›¿æ¢ä¸ºæ‚¨çš„å®é™…å¯†ç  !!!
    'database': 'ojld'
}

# --- è¡¨å®šä¹‰ (ä¸ä¹‹å‰ç›¸åŒ) ---
TABLES = {}
TABLES['Subjects'] = (
    "CREATE TABLE IF NOT EXISTS `Subjects` ("
    "  `SubjectID` INT AUTO_INCREMENT PRIMARY KEY,"
    "  `SubjectName` VARCHAR(100) NOT NULL UNIQUE"
    ") ENGINE=InnoDB")

TABLES['Books'] = (
    "CREATE TABLE IF NOT EXISTS `Books` ("
    "  `ID` INT AUTO_INCREMENT PRIMARY KEY,"
    "  `BookID` INT NOT NULL UNIQUE,"
    "  `BookTitle` VARCHAR(255) NOT NULL,"
    "  `SubjectID` INT NOT NULL,"
    "  `SourceJsonFileName` VARCHAR(255) NULL,"
    "  `Description` TEXT NULL,"
    "  `CreationTimestamp` TIMESTAMP DEFAULT CURRENT_TIMESTAMP,"
    "  `VersionInfo` VARCHAR(100) NULL,"
    "  `LearnerCount` INT NULL,"
    "  `StyleType` VARCHAR(20) NULL,"
    "  `IsNew` BOOLEAN NULL DEFAULT FALSE,"
    "  `OverlayBannerText` VARCHAR(100) NULL,"
    "  `ThumbnailText` VARCHAR(100) NULL,"
    "  FOREIGN KEY (`SubjectID`) REFERENCES `Subjects`(`SubjectID`) ON DELETE RESTRICT ON UPDATE CASCADE,"
    "  INDEX `idx_books_bookid_meaningful` (`BookID`)"
    ") ENGINE=InnoDB")

TABLES['Questions'] = (
    "CREATE TABLE IF NOT EXISTS `Questions` ("
    "  `ID` INT AUTO_INCREMENT PRIMARY KEY,"
    "  `QuestionID` INT NOT NULL UNIQUE COMMENT 'æ¥è‡ªå¤–éƒ¨æºçš„å”¯ä¸€å…¨å±€é—®é¢˜æ ‡è¯†ç¬¦',"
    "  `QuestionText` TEXT NULL,"
    "  `OriginalAnswerText` TEXT NULL,"
    "  `LegacyOriginalBookID` INT NULL,"
    "  `LegacyOriginalQuestionSort` VARCHAR(50) NULL,"
    "  `LinksCount` VARCHAR(255) NULL,"
    "  `LinkNames` TEXT NULL,"
    "  INDEX `idx_questions_questionid_meaningful` (`QuestionID`)"
    ") ENGINE=InnoDB")

TABLES['BookQuestions'] = (
    "CREATE TABLE IF NOT EXISTS `BookQuestions` ("
    "  `EntryID` INT NOT NULL PRIMARY KEY COMMENT 'æœ¬ä¹¦ç±-é—®é¢˜æ¡ç›®çš„å”¯ä¸€ID (æ¥è‡ªJSONçš„IDå­—æ®µ)',"
    "  `BookID` INT NOT NULL COMMENT 'æ¥è‡ªJSONçš„ä¸Šä¸‹æ–‡ä¹¦ç±ID',"
    "  `QuestionID` INT NOT NULL COMMENT 'æ¥è‡ªJSONçš„ä¸Šä¸‹æ–‡é—®é¢˜ID',"
    "  `QuestionPage` VARCHAR(20) NULL,"
    "  `QuestionSort` VARCHAR(10) NULL COMMENT 'æ¥è‡ªJSONçš„é¡µé¢/ç« èŠ‚ç‰¹å®šæ’åº (å¯é‡å¤)',"
    "  `Sort` INT NULL COMMENT 'æœ¬ä¹¦åœ¨æ­¤ä¸Šä¸‹æ–‡ä¸­é—®é¢˜çš„æ•´ä½“æ’åºé¡ºåº/ç¼–å· (æ¥è‡ªJSONçš„Sort - ä¸åŒEntryIDå¯é‡å¤)',"
    "  `ChapterName` VARCHAR(255) NULL,"
    "  `BookChapter` VARCHAR(255) NULL,"
    "  `ChapterSort` INT NULL,"
    "  `QuestionImg` VARCHAR(512) NULL,"
    "  INDEX `idx_bq_bookid` (`BookID`),"
    "  INDEX `idx_bq_questionid` (`QuestionID`),"
    "  INDEX `idx_bq_bookid_sort` (`BookID`, `Sort`)"
    ") ENGINE=InnoDB COMMENT='å°†ä¹¦ç±ä¸é—®é¢˜åŠå…¶ä¸Šä¸‹æ–‡é“¾æ¥ã€‚EntryIDå”¯ä¸€ (JSON ID)ã€‚Sortå¯é‡å¤ã€‚'")

TABLES['KnowledgePoints'] = (
    "CREATE TABLE IF NOT EXISTS `KnowledgePoints` ("
    "  `KnowledgePointID` INT AUTO_INCREMENT PRIMARY KEY,"
    "  `KPCode` VARCHAR(50) UNIQUE COMMENT 'å¦‚æœæ˜¯è‡ªç„¶é”®ï¼Œæ•°æ®å¯¼å…¥åº”åœ¨æ­¤é”®ä¸Šä½¿ç”¨ON DUPLICATE KEY UPDATE',"
    "  `KPTitle` VARCHAR(255) NOT NULL,"
    "  `KPContent` TEXT,"
    "  `KPType` VARCHAR(50),"
    "  `KPBusType` VARCHAR(50),"
    "  `KPPCode` VARCHAR(50),"
    "  `KPNotes` TEXT,"
    "  `KPOutlineType` VARCHAR(50),"
    "  `KPDifficultyType` VARCHAR(50)"
    ") ENGINE= InnoDB")

TABLES['QuestionDetails'] = (
    "CREATE TABLE IF NOT EXISTS `QuestionDetails` ("
    "  `ID` INT AUTO_INCREMENT PRIMARY KEY,"
    "  `QuestionID` INT NOT NULL,"
    "  `BusType` VARCHAR(50) NOT NULL,"
    "  `Context` TEXT,"
    "  `Give` INT,"
    "  `Notes` TEXT,"
    "  `JsonData` TEXT,"
    "  `Title` VARCHAR(255),"
    "  `IsProductBook` BOOLEAN DEFAULT 0,"
    "  `LinkedKnowledgePointID` INT NULL,"
    "  `SourceDetailID` INT NULL COMMENT 'JSON second_requestæ¡ç›®çš„åŸå§‹IDï¼Œä¾›å‚è€ƒ',"
    "  FOREIGN KEY (`LinkedKnowledgePointID`) REFERENCES `KnowledgePoints`(`KnowledgePointID`) ON DELETE SET NULL ON UPDATE CASCADE,"
    "  UNIQUE KEY `UQ_QuestionDetailItem` (`QuestionID`, `BusType`, `SourceDetailID`) COMMENT 'å‡è®¾SourceDetailIDåœ¨QuestionIDå’ŒBusTypeä¸Šä¸‹æ–‡ä¸­æ˜¯å”¯ä¸€çš„',"
    "  INDEX `idx_qdetails_questionid` (`QuestionID`)"
    ") ENGINE=InnoDB")

TABLES['RelatedQuestions'] = (
    "CREATE TABLE IF NOT EXISTS `RelatedQuestions` ("
    "  `ID` INT AUTO_INCREMENT PRIMARY KEY,"
    "  `SourceQuestionID` INT NOT NULL,"
    "  `RelatedQuestionOriginalID` VARCHAR(50) NOT NULL COMMENT 'ç›¸å…³é—®é¢˜çš„æ ‡è¯†ç¬¦ (ä¾‹å¦‚å¦ä¸€ä¸ªQuestionID)',"
    "  `RelatedQuestionText` TEXT NULL,"
    "  `LinkNames` TEXT NULL,"
    "  `FocalLink` INT NULL,"
    "  `QuestionPage` VARCHAR(20) NULL,"
    "  `SourceThirdRequestID` INT NULL COMMENT 'JSON third_requestæ¡ç›®çš„åŸå§‹IDï¼Œä¾›å‚è€ƒ',"
    "  UNIQUE KEY `UQ_RelatedQuestionPair` (`SourceQuestionID`, `RelatedQuestionOriginalID`) COMMENT 'é˜²æ­¢ä¸ºæºé—®é¢˜é‡å¤æ·»åŠ ç›¸åŒçš„ç›¸å…³é—®é¢˜é“¾æ¥',"
    "  INDEX `idx_relatedq_sourceqid` (`SourceQuestionID`)"
    ") ENGINE=InnoDB")

TABLE_PROCESSING_ORDER = [
    'RelatedQuestions', 'BookQuestions', 'QuestionDetails', 'KnowledgePoints', 'Questions', 'Books', 'Subjects'
]


# --- åå°å·¥ä½œçº¿ç¨‹ ---
class WorkerThread(QThread):
    signal_log = pyqtSignal(str)
    signal_finished = pyqtSignal(str)
    signal_progress_max = pyqtSignal(int)
    signal_progress_value = pyqtSignal(int)
    signal_populate_book_combo = pyqtSignal(list)

    def __init__(self, task_type, **kwargs):
        super().__init__()
        self.task_type = task_type
        self.kwargs = kwargs
        self.cnx = None
        self.cursor = None

    def connect_db(self):
        try:
            self.cnx = mysql.connector.connect(**DB_CONFIG)
            self.cursor = self.cnx.cursor(dictionary=True)
            self.signal_log.emit(f"æˆåŠŸè¿æ¥åˆ°æ•°æ®åº“ '{DB_CONFIG['database']}'.")
            return True
        except mysql.connector.Error as err:
            self.signal_log.emit(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {err}")
            self.signal_finished.emit(f"æ•°æ®åº“è¿æ¥é”™è¯¯: {err}")
            return False
        except Exception as e:
            self.signal_log.emit(f"æ•°æ®åº“è¿æ¥ - æœªçŸ¥é”™è¯¯: {e}")
            self.signal_finished.emit(f"æ•°æ®åº“è¿æ¥ - æœªçŸ¥é”™è¯¯: {e}")
            return False

    def close_db(self):
        if self.cursor: self.cursor.close()
        if self.cnx and self.cnx.is_connected(): self.cnx.close()
        self.signal_log.emit(f"ä¸æ•°æ®åº“ '{DB_CONFIG['database']}' çš„è¿æ¥å·²å…³é—­ã€‚")

    def run(self):
        if not self.connect_db():
            return

        try:
            if self.task_type == "reset_schema":
                self.reset_schema_task()
            elif self.task_type == "import_book_json":
                self.import_book_json_task()
            elif self.task_type == "import_quest_json":
                self.import_quest_json_task()
            elif self.task_type == "fetch_books":
                self.fetch_books_task()
        except Exception as e:
            error_msg = f"ä»»åŠ¡ '{self.task_type}' æ‰§è¡Œå‡ºé”™: {e}\n{traceback.format_exc()}"
            self.signal_log.emit(error_msg)
            self.signal_finished.emit(f"ä»»åŠ¡ '{self.task_type}' å¤±è´¥ã€‚è¯¦æƒ…è¯·æŸ¥çœ‹æ—¥å¿—ã€‚")
        finally:
            self.close_db()

    def reset_schema_task(self):
        self.signal_log.emit("å¼€å§‹é‡ç½®å¹¶åˆ›å»ºæ•°æ®åº“ç»“æ„...")
        try:
            self.signal_log.emit("\n--- æ­£åœ¨åˆ é™¤æ‰€æœ‰ç°æœ‰è¡¨ ---")
            self.cursor.execute("SET FOREIGN_KEY_CHECKS = 0;")
            for table_name in TABLE_PROCESSING_ORDER:
                self.signal_log.emit(f"æ­£åœ¨åˆ é™¤è¡¨ `{table_name}`... ")
                self.cursor.execute(f"DROP TABLE IF EXISTS `{table_name}`")
            self.cursor.execute("SET FOREIGN_KEY_CHECKS = 1;")
            self.cnx.commit()
            self.signal_log.emit("å®Œæˆåˆ é™¤è¡¨ã€‚")

            creation_order = TABLE_PROCESSING_ORDER[::-1]
            self.signal_log.emit("\n--- æ­£åœ¨åˆ›å»ºè¡¨ ---")
            for table_name in creation_order:
                if table_name not in TABLES:
                    self.signal_log.emit(f"è­¦å‘Š: æœªæ‰¾åˆ°è¡¨ '{table_name}' çš„å®šä¹‰ã€‚è·³è¿‡ã€‚")
                    continue
                self.signal_log.emit(f"æ­£åœ¨åˆ›å»ºè¡¨ `{table_name}`... ")
                self.cursor.execute(TABLES[table_name])
            self.cnx.commit()
            self.signal_log.emit("è¡¨å·²åˆ›å»ºã€‚")

            self.signal_log.emit("\n--- æ­£åœ¨é¢„å¡«å…… Subjects è¡¨ ---")
            for subject_name in ["æ•°å­¦ä¸€", "æ•°å­¦äºŒ", "æ•°å­¦ä¸‰"]:  # ä½¿ç”¨ä¸­æ–‡
                self.cursor.execute("INSERT IGNORE INTO Subjects (SubjectName) VALUES (%s)", (subject_name,))
            self.cnx.commit()
            self.signal_log.emit("Subjects è¡¨é¢„å¡«å……å®Œæˆã€‚")
            self.signal_finished.emit("æ•°æ®åº“ç»“æ„é‡ç½®å¹¶åˆ›å»ºæˆåŠŸï¼")

        except mysql.connector.Error as err:
            self.signal_log.emit(f"æ•°æ®åº“ç»“æ„é‡ç½®æœŸé—´å‘ç”ŸMySQLé”™è¯¯: {err}")
            self.signal_finished.emit(f"æ•°æ®åº“ç»“æ„é‡ç½®å¤±è´¥: {err}")
            try:
                self.cursor.execute("SET FOREIGN_KEY_CHECKS = 1;")
            except:
                pass
        except Exception as e:
            self.signal_log.emit(f"æ•°æ®åº“ç»“æ„é‡ç½®æœŸé—´å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}\n{traceback.format_exc()}")
            self.signal_finished.emit(f"æ•°æ®åº“ç»“æ„é‡ç½®æ„å¤–å¤±è´¥ã€‚")

    def import_book_json_task(self):
        json_file_path = self.kwargs.get('json_file_path')
        self.signal_log.emit(f"å¼€å§‹ä» `book.json` å¯¼å…¥: {json_file_path}")
        # ... (ä¸ä¹‹å‰ç›¸åŒçš„å¯¼å…¥ book.json çš„é€»è¾‘, ä½†æ—¥å¿—ä¿¡æ¯ä½¿ç”¨ä¸­æ–‡)
        # ä¾‹å¦‚: self.signal_log.emit("æ­£åœ¨å¤„ç†ä¹¦ç±ä¿¡æ¯ä»¥ç¡®ä¿å­˜åœ¨äº Books è¡¨...")
        # ç¡®ä¿ _ensure_books_exist_from_book_json, _ensure_questions_exist_from_book_json,
        # _insert_book_question_data_from_book_json ä¸­çš„ self.signal_log.emit() ä¹Ÿä½¿ç”¨ä¸­æ–‡
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                all_books_data = json.load(f)
            if not isinstance(all_books_data, list):
                self.signal_log.emit(f"é”™è¯¯: '{json_file_path}' çš„JSONæ ¹èŠ‚ç‚¹ä¸æ˜¯åˆ—è¡¨ã€‚")
                self.signal_finished.emit(f"ä» '{os.path.basename(json_file_path)}' å¯¼å…¥å¤±è´¥: JSONç»“æ„æ— æ•ˆã€‚")
                return

            self.signal_log.emit("æ­£åœ¨ä»book.jsonç¡®ä¿ä¹¦ç±å’Œæœ€å°‘é—®é¢˜æ¡ç›®å­˜åœ¨...")
            s_books, f_books = self._ensure_books_exist_from_book_json(all_books_data)
            s_qs, f_qs = self._ensure_questions_exist_from_book_json(all_books_data)
            self.signal_log.emit(f"ä¹¦ç±ç¡®ä¿: {s_books} æˆåŠŸ, {f_books} å¤±è´¥ã€‚")
            self.signal_log.emit(f"æœ€å°‘é—®é¢˜æ¡ç›®ç¡®ä¿: {s_qs} æ–°å¢, {f_qs} å¤±è´¥ã€‚")

            self.signal_log.emit("\n--- æ­£åœ¨ä» book.json ä¸Šä¼  BookQuestions æ•°æ® ---")
            total_items = sum(len(book_list) for book_list in all_books_data if isinstance(book_list, list))
            self.signal_progress_max.emit(total_items)
            current_progress = 0
            total_bq_successful_ops = 0
            total_bq_failed_ops = 0

            self.cursor.execute("SET SESSION foreign_key_checks = 0;")
            for book_index, single_book_question_list in enumerate(all_books_data):
                if not isinstance(single_book_question_list, list):
                    self.signal_log.emit(f"è­¦å‘Š: JSONç´¢å¼• {book_index} å¤„çš„æ¡ç›®ä¸æ˜¯åˆ—è¡¨ã€‚è·³è¿‡ã€‚");
                    continue

                s_ops, f_ops = self._insert_book_question_data_from_book_json(single_book_question_list)
                total_bq_successful_ops += s_ops;
                total_bq_failed_ops += f_ops
                current_progress += len(single_book_question_list)
                self.signal_progress_value.emit(current_progress)

            if total_bq_successful_ops > 0 or total_bq_failed_ops > 0:
                self.cnx.commit();
                self.signal_log.emit("å·²æäº¤ BookQuestions æ“ä½œã€‚")
            self.cursor.execute("SET SESSION foreign_key_checks = 1;")

            self.signal_log.emit(f"\n--- `book.json` å¯¼å…¥æ‘˜è¦ ---")
            self.signal_log.emit(f"BookQuestions æ€»æˆåŠŸæ“ä½œæ•°: {total_bq_successful_ops}")
            self.signal_log.emit(f"BookQuestions æ€»å¤±è´¥æ“ä½œæ•°: {total_bq_failed_ops}")
            self.signal_finished.emit(f"ä» '{os.path.basename(json_file_path)}' å¯¼å…¥å®Œæˆã€‚è¯¦æƒ…è¯·æŸ¥çœ‹æ—¥å¿—ã€‚")

        except json.JSONDecodeError as je:  # ... (é”™è¯¯å¤„ç†ä¿æŒä¸å˜, ä½†æ¶ˆæ¯å¯èƒ½æ˜¯ä¸­æ–‡)
            self.signal_log.emit(f"è§£ç  {json_file_path} å‡ºé”™: {je}")
            self.signal_finished.emit(f"å¯¼å…¥å¤±è´¥: '{os.path.basename(json_file_path)}' JSONè§£ç é”™è¯¯ã€‚")
        except mysql.connector.Error as err:
            self.signal_log.emit(f"book.jsonå¯¼å…¥æœŸé—´MySQLé”™è¯¯: {err}")
            self.signal_finished.emit(f"å¯¼å…¥å¤±è´¥: MySQLé”™è¯¯ã€‚ {err.msg}")
        except Exception as e:
            self.signal_log.emit(f"book.jsonå¯¼å…¥æœŸé—´æœªçŸ¥é”™è¯¯: {e}\n{traceback.format_exc()}")
            self.signal_finished.emit(f"å¯¼å…¥æ„å¤–å¤±è´¥ã€‚è¯¦æƒ…è¯·æŸ¥çœ‹æ—¥å¿—ã€‚")

    def _ensure_books_exist_from_book_json(self, all_book_question_items):
        self.signal_log.emit("æ­£åœ¨å¤„ç†å”¯ä¸€ä¹¦ç±ä»¥å­˜å…¥ Books è¡¨...")
        unique_books = {}
        for book_list in all_book_question_items:
            for item in book_list:
                book_id = item.get('BookID')
                book_name = item.get('BookName')
                if book_id is not None and book_name is not None:
                    if book_id not in unique_books:
                        subject_id_for_book = item.get('SubjectID')
                        if subject_id_for_book is None:
                            if "æ•°ä¸€" in book_name or "æ•°å­¦ä¸€" in book_name:
                                subject_id_for_book = 1
                            elif "æ•°äºŒ" in book_name or "æ•°å­¦äºŒ" in book_name:
                                subject_id_for_book = 2
                            elif "æ•°ä¸‰" in book_name or "æ•°å­¦ä¸‰" in book_name:
                                subject_id_for_book = 3
                            else:
                                subject_id_for_book = 1
                            self.signal_log.emit(f"  BookID {book_id}: æ¨æµ‹ SubjectID ä¸º {subject_id_for_book} (è¯·æ ¸å®)ã€‚")
                        unique_books[book_id] = {
                            'BookID': book_id, 'BookTitle': book_name, 'SubjectID': subject_id_for_book,
                            'VersionInfo': item.get('VersionInfo'), 'LearnerCount': item.get('LearnerCount'),
                            'StyleType': item.get('StyleType'), 'IsNew': item.get('IsNew', False),
                            'OverlayBannerText': item.get('OverlayBannerText'),
                            'ThumbnailText': item.get('ThumbnailText', book_name[:20])}
        if not unique_books: self.signal_log.emit("book.jsonä¸­æ²¡æœ‰å”¯ä¸€çš„ä¹¦ç±ä¿¡æ¯ã€‚"); return 0, 0
        insert_book_sql = """
            INSERT INTO Books (BookID, BookTitle, SubjectID, VersionInfo, LearnerCount, StyleType, IsNew, OverlayBannerText, ThumbnailText)
            VALUES (%(BookID)s, %(BookTitle)s, %(SubjectID)s, %(VersionInfo)s, %(LearnerCount)s, %(StyleType)s, %(IsNew)s, %(OverlayBannerText)s, %(ThumbnailText)s)
            ON DUPLICATE KEY UPDATE BookTitle=VALUES(BookTitle), SubjectID=VALUES(SubjectID), VersionInfo=VALUES(VersionInfo), LearnerCount=VALUES(LearnerCount), StyleType=VALUES(StyleType), IsNew=VALUES(IsNew), OverlayBannerText=VALUES(OverlayBannerText), ThumbnailText=VALUES(ThumbnailText);"""
        s, f = 0, 0
        for book_id, book_details in unique_books.items():
            try:
                self.cursor.execute(insert_book_sql, book_details); s += 1
            except mysql.connector.Error as err:
                self.signal_log.emit(f"  å¤„ç† BookID {book_id} (Booksè¡¨) æ—¶å‡ºé”™: {err}"); f += 1
        if s > 0 or f > 0: self.cnx.commit()
        return s, f

    def _ensure_questions_exist_from_book_json(self, all_book_question_items):
        self.signal_log.emit("æ­£åœ¨å¤„ç†å”¯ä¸€QuestionIDä»¥å­˜å…¥ Questions è¡¨ (æœ€å°‘ä¿¡æ¯)...")
        unique_question_ids = set()
        for book_list in all_book_question_items:
            for item in book_list:
                qid = item.get('QuestionID');
                if qid is not None: unique_question_ids.add(qid)
        if not unique_question_ids: self.signal_log.emit("book.jsonä¸­æ²¡æœ‰QuestionIDã€‚"); return 0, 0
        insert_question_sql = "INSERT IGNORE INTO Questions (QuestionID, QuestionText) VALUES (%s, NULL);"
        s, f = 0, 0
        for qid in unique_question_ids:
            try:
                self.cursor.execute(insert_question_sql, (qid,))
                if self.cursor.rowcount == 1: s += 1
            except mysql.connector.Error as err:
                self.signal_log.emit(f"  å¤„ç† QID {qid} (Questionsè¡¨) æ—¶å‡ºé”™: {err}"); f += 1
        if s > 0 or f > 0: self.cnx.commit()
        return s, f

    def _insert_book_question_data_from_book_json(self, book_data_list):
        insert_sql = """
            INSERT INTO BookQuestions (EntryID, BookID, QuestionID, QuestionPage, QuestionSort, Sort, ChapterName, BookChapter, ChapterSort, QuestionImg) 
            VALUES (%(EntryID)s, %(BookID)s, %(QuestionID)s, %(QuestionPage)s, %(QuestionSort)s, %(Sort)s, %(ChapterName)s, %(BookChapter)s, %(ChapterSort)s, %(QuestionImg)s)
            ON DUPLICATE KEY UPDATE BookID=VALUES(BookID), QuestionID=VALUES(QuestionID), QuestionPage=VALUES(QuestionPage), QuestionSort=VALUES(QuestionSort), Sort=VALUES(Sort), ChapterName=VALUES(ChapterName), BookChapter=VALUES(BookChapter), ChapterSort=VALUES(ChapterSort), QuestionImg=VALUES(QuestionImg);"""
        s, f = 0, 0
        for item in book_data_list:
            entry_id = item.get('ID')
            if entry_id is None: self.signal_log.emit("è·³è¿‡æ¡ç›®: JSON 'ID' (ç”¨äºEntryID) ç¼ºå¤±ã€‚"); f += 1; continue
            img_url = item.get('QuestionImg');
            if img_url and img_url.endswith('_yjs'): img_url = img_url[:-4]
            data = {'EntryID': entry_id, 'BookID': item.get('BookID'), 'QuestionID': item.get('QuestionID'),
                    'QuestionPage': item.get('QuestionPage'), 'QuestionSort': item.get('QuestionSort'),
                    'Sort': item.get('Sort'),
                    'ChapterName': item.get('ChapterName'), 'BookChapter': item.get('BookChapter'),
                    'ChapterSort': item.get('ChapterSort'), 'QuestionImg': img_url}
            try:
                self.cursor.execute(insert_sql, data); s += 1
            except mysql.connector.Error as err:
                self.signal_log.emit(f"  å¤„ç† BookQuestions (EntryID {entry_id}) æ—¶å‡ºé”™: {err.msg}\n    æ•°æ®: {data}"); f += 1
        return s, f

    def import_quest_json_task(self):
        json_file_path = self.kwargs.get('json_file_path')
        target_book_meaningful_id = self.kwargs.get('target_book_meaningful_id')
        is_new_book = self.kwargs.get('is_new_book', False)
        book_title_for_log = self.kwargs.get('book_title_for_log', f"BookID {target_book_meaningful_id}")

        self.signal_log.emit(
            f"å¼€å§‹ä» `quest.json` å¯¼å…¥: {json_file_path}ï¼Œç›®æ ‡ä¹¦ç±: '{book_title_for_log}' (Meaningful BookID: {target_book_meaningful_id})")
        try:
            with open(json_file_path, 'r', encoding='utf-8') as f:
                all_quest_data_dict = json.load(f)
            if not isinstance(all_quest_data_dict, dict):
                self.signal_log.emit(f"é”™è¯¯: '{json_file_path}' çš„JSONæ ¹èŠ‚ç‚¹å¿…é¡»æ˜¯å­—å…¸ã€‚")
                self.signal_finished.emit(f"å¯¼å…¥å¤±è´¥: '{os.path.basename(json_file_path)}' JSONç»“æ„æ— æ•ˆã€‚")
                return

            self.signal_log.emit("æ­£åœ¨ä»quest.jsonå¡«å……/æ›´æ–°å…¨å±€Questionsè¡¨...")
            s_global_q, f_global_q = self._insert_global_questions_from_quest_json(all_quest_data_dict)
            self.signal_log.emit(f"å…¨å±€Questions: {s_global_q} æˆåŠŸ, {f_global_q} å¤±è´¥ã€‚")

            self.signal_log.emit(
                f"\næ­£åœ¨ä» '{os.path.basename(json_file_path)}' å¤„ç† {len(all_quest_data_dict)} ä¸ªé—®é¢˜çš„è¯¦ç»†ä¿¡æ¯...")
            self.signal_progress_max.emit(len(all_quest_data_dict))

            stats = self._insert_data_from_quest_json_details(target_book_meaningful_id, all_quest_data_dict,
                                                              is_new_book)

            self.signal_log.emit(f"\n--- `quest.json` å¯¼å…¥æ‘˜è¦ (ä¹¦ç± '{book_title_for_log}') ---")
            for table_key, counts in stats.items():
                name_map = {"bq_link": "ä¹¦ç±é—®é¢˜é“¾æ¥ (BookQuestions)", "kp": "çŸ¥è¯†ç‚¹ (KnowledgePoints)",
                            "qd": "é—®é¢˜è¯¦æƒ… (QuestionDetails)", "rq": "ç›¸å…³é—®é¢˜ (RelatedQuestions)"}
                name = name_map.get(table_key, table_key.capitalize())
                self.signal_log.emit(
                    f"{name}: {counts.get('s', 0)} æ–°å¢, {counts.get('updated', 0)} æ›´æ–°, {counts.get('skipped_no_change', 0)} è·³è¿‡(æ— å˜åŒ–), {counts.get('f', 0)} å¤±è´¥ã€‚")
            self.signal_finished.emit(f"ä» '{os.path.basename(json_file_path)}' ä¸º '{book_title_for_log}' å¯¼å…¥å®Œæˆã€‚")

        except json.JSONDecodeError as je:
            self.signal_log.emit(f"è§£ç  {json_file_path} å‡ºé”™: {je}")
            self.signal_finished.emit(f"å¯¼å…¥å¤±è´¥: '{os.path.basename(json_file_path)}' JSONè§£ç é”™è¯¯ã€‚")
        except mysql.connector.Error as err:
            self.signal_log.emit(f"quest.jsonå¯¼å…¥æœŸé—´MySQLé”™è¯¯: {err}")
            self.signal_finished.emit(f"å¯¼å…¥å¤±è´¥: MySQLé”™è¯¯ã€‚ {err.msg}")
        except Exception as e:
            self.signal_log.emit(f"quest.jsonå¯¼å…¥æœŸé—´æœªçŸ¥é”™è¯¯: {e}\n{traceback.format_exc()}")
            self.signal_finished.emit(f"å¯¼å…¥æ„å¤–å¤±è´¥ã€‚è¯¦æƒ…è¯·æŸ¥çœ‹æ—¥å¿—ã€‚")

    def _get_safe_from_dict(self, data_dict, key, default=None):
        val = data_dict.get(key)
        return default if val is None else val

    def _insert_global_questions_from_quest_json(self, quest_json_data_dict):
        sql_question = """
            INSERT INTO Questions (QuestionID, QuestionText, OriginalAnswerText, LegacyOriginalBookID, LegacyOriginalQuestionSort, LinksCount, LinkNames) 
            VALUES (%(QuestionID)s, %(QuestionText)s, %(OriginalAnswerText)s, %(LegacyOriginalBookID)s, %(LegacyOriginalQuestionSort)s, %(LinksCount)s, %(LinkNames)s)
            ON DUPLICATE KEY UPDATE QuestionText=VALUES(QuestionText), OriginalAnswerText=VALUES(OriginalAnswerText), LegacyOriginalBookID=VALUES(LegacyOriginalBookID), LegacyOriginalQuestionSort=VALUES(LegacyOriginalQuestionSort), LinksCount=VALUES(LinksCount), LinkNames=VALUES(LinkNames);"""
        s, f = 0, 0
        for qid_str, q_content in quest_json_data_dict.items():
            val_q = {};
            fr = q_content.get('first_request', [{}])[0]
            try:
                if not fr: self.signal_log.emit(f"  è·³è¿‡QID {qid_str} (Questionsè¡¨): æ— first_requestæ•°æ®ã€‚"); f += 1; continue
                qid_int = int(qid_str)
                val_q = {'QuestionID': qid_int, 'QuestionText': self._get_safe_from_dict(fr, 'QuestionTxt'),
                         'OriginalAnswerText': self._get_safe_from_dict(fr, 'AnswerTxt'),
                         'LegacyOriginalBookID': self._get_safe_from_dict(fr, 'BookID'),
                         'LegacyOriginalQuestionSort': self._get_safe_from_dict(fr, 'QuestionID'),
                         'LinksCount': self._get_safe_from_dict(fr, 'LinksCount'),
                         'LinkNames': self._get_safe_from_dict(fr, 'LinkNames')}
                self.cursor.execute(sql_question, val_q);
                s += 1
            except ValueError:
                self.signal_log.emit(f"  è·³è¿‡QID '{qid_str}': éæœ‰æ•ˆæ•´æ•°ã€‚"); f += 1
            except mysql.connector.Error as err:
                self.signal_log.emit(f"  å¤„ç†Questions (QID {qid_str})æ—¶MySQLé”™è¯¯: {err.msg}"); f += 1
        if s > 0 or f > 0: self.cnx.commit()
        return s, f

    def _insert_data_from_quest_json_details(self, target_meaningful_book_id, all_questions_data_dict, is_new_book):
        stats = {'bq_link': {'s': 0, 'f': 0, 'updated': 0, 'skipped_no_change': 0},
                 'kp': {'s': 0, 'f': 0}, 'qd': {'s': 0, 'f': 0}, 'rq': {'s': 0, 'f': 0}}
        question_order = 0
        self.cursor.execute("SET SESSION foreign_key_checks = 0;")

        for qid_str_key, q_content in all_questions_data_dict.items():
            question_order += 1;
            self.signal_progress_value.emit(question_order)
            self.signal_log.emit(f"\næ­£åœ¨å¤„ç†æ¥è‡ªquest.jsonçš„QID: {qid_str_key} (ä¹¦ç±å†…é¡ºåº: {question_order})")
            global_qid = None
            try:
                global_qid = int(qid_str_key)
            except ValueError:
                self.signal_log.emit(f"  è·³è¿‡QID '{qid_str_key}': éæœ‰æ•ˆæ•´æ•°ã€‚"); continue

            fr_item_bq = q_content.get('first_request', [{}])[0]
            bq_page = self._get_safe_from_dict(fr_item_bq, 'QuestionPage')
            bq_sort_str = self._get_safe_from_dict(fr_item_bq, 'QuestionID')

            existing_bq_id = None
            if not is_new_book:
                self.cursor.execute("SELECT EntryID FROM BookQuestions WHERE BookID = %s AND QuestionID = %s LIMIT 1",
                                    (target_meaningful_book_id, global_qid))
                row = self.cursor.fetchone()
                if row: existing_bq_id = row['EntryID']

            if existing_bq_id:
                update_fields_bq = {};
                if bq_page is not None: update_fields_bq['QuestionPage'] = bq_page
                if bq_sort_str is not None: update_fields_bq['QuestionSort'] = bq_sort_str
                if update_fields_bq:
                    set_clause = ", ".join([f"`{k}` = %({k})s" for k in update_fields_bq])
                    sql_upd_bq = f"UPDATE BookQuestions SET {set_clause} WHERE EntryID = %(EntryID)s"
                    update_fields_bq['EntryID'] = existing_bq_id
                    try:
                        self.cursor.execute(sql_upd_bq, update_fields_bq); stats['bq_link'][
                            'updated' if self.cursor.rowcount > 0 else 'skipped_no_change'] += 1
                    except mysql.connector.Error as err:
                        stats['bq_link']['f'] += 1; self.signal_log.emit(f"  æ›´æ–°BQ {existing_bq_id}å‡ºé”™: {err.msg}")
                else:
                    stats['bq_link']['skipped_no_change'] += 1
            elif is_new_book:  # Only create BQ link if it's a new book being populated from quest.json
                sql_ins_bq = """INSERT INTO BookQuestions (EntryID, BookID, QuestionID, QuestionPage, QuestionSort, Sort) 
                                 VALUES (%(EntryID)s, %(BookID)s, %(QuestionID)s, %(QuestionPage)s, %(QuestionSort)s, %(Sort)s)
                                 ON DUPLICATE KEY UPDATE QuestionPage=VALUES(QuestionPage), QuestionSort=VALUES(QuestionSort), Sort=VALUES(Sort)"""
                val_bq_ins = {'EntryID': -global_qid, 'BookID': target_meaningful_book_id, 'QuestionID': global_qid,
                              'QuestionPage': bq_page, 'QuestionSort': bq_sort_str, 'Sort': question_order}
                try:
                    self.cursor.execute(sql_ins_bq, val_bq_ins); stats['bq_link']['s'] += 1
                except mysql.connector.Error as err:
                    stats['bq_link']['f'] += 1; self.signal_log.emit(f"  ä¸ºæ–°ä¹¦æ’å…¥BQ (QID {global_qid})å‡ºé”™: {err.msg}")
            else:  # Existing book, but no link found from book.json. Log, but don't create from quest.json unless explicit.
                self.signal_log.emit(
                    f"  è­¦å‘Š: BookID {target_meaningful_book_id} ä¸ QID {global_qid} çš„BookQuestionsé“¾æ¥æœªåœ¨book.jsonä¸­æ‰¾åˆ°ã€‚è¯¦æƒ…å¯èƒ½å­¤ç«‹ã€‚")

            if q_content.get('second_request'):
                for sr_item in q_content['second_request']:
                    linked_kp_db_id = None
                    if sr_item.get('_question_code') and sr_item['_question_code'].get('Code'):
                        kp_code = sr_item['_question_code']['Code']
                        qc_data = sr_item['_question_code']
                        val_kp = {'KPCode': kp_code,
                                  'KPTitle': self._get_safe_from_dict(qc_data, 'Title', f"KP {kp_code}"),
                                  'KPContent': self._get_safe_from_dict(qc_data, 'Content'),
                                  'KPType': self._get_safe_from_dict(qc_data, 'Type'),
                                  'KPBusType': self._get_safe_from_dict(qc_data, 'BusType'),
                                  'KPPCode': self._get_safe_from_dict(qc_data, 'PCode'),
                                  'KPNotes': self._get_safe_from_dict(qc_data, 'Notes'),
                                  'KPOutlineType': self._get_safe_from_dict(qc_data, 'OutlineType'),
                                  'KPDifficultyType': self._get_safe_from_dict(qc_data, 'DifficultyType')}
                        sql_kp = "INSERT INTO KnowledgePoints (KPCode, KPTitle, KPContent, KPType, KPBusType, KPPCode, KPNotes, KPOutlineType, KPDifficultyType) VALUES (%(KPCode)s, %(KPTitle)s, %(KPContent)s, %(KPType)s, %(KPBusType)s, %(KPPCode)s, %(KPNotes)s, %(KPOutlineType)s, %(KPDifficultyType)s) ON DUPLICATE KEY UPDATE KPTitle=VALUES(KPTitle), KPContent=VALUES(KPContent), KPType=VALUES(KPType), KPBusType=VALUES(KPBusType), KPPCode=VALUES(KPPCode), KPNotes=VALUES(KPNotes), KPOutlineType=VALUES(KPOutlineType), KPDifficultyType=VALUES(KPDifficultyType);"
                        try:
                            self.cursor.execute(sql_kp, val_kp); stats['kp']['s'] += 1
                        except mysql.connector.Error as err:
                            stats['kp']['f'] += 1; self.signal_log.emit(f"  å¤„ç†KP {kp_code}å‡ºé”™: {err.msg}")
                        if stats['kp']['s'] > 0:  # Assume success if no error, then fetch ID
                            self.cursor.execute("SELECT KnowledgePointID FROM KnowledgePoints WHERE KPCode = %s",
                                                (kp_code,))
                            kp_res = self.cursor.fetchone();
                            if kp_res: linked_kp_db_id = kp_res['KnowledgePointID']

                    src_detail_id = self._get_safe_from_dict(sr_item, 'ID');
                    bus_type = self._get_safe_from_dict(sr_item, 'BusType', 'N/A')
                    if src_detail_id is None: stats['qd']['f'] += 1; self.signal_log.emit(
                        "  è·³è¿‡QD: SourceDetailIDç¼ºå¤±ã€‚"); continue
                    json_data_val = self._get_safe_from_dict(sr_item, 'Json');
                    json_str = json.dumps(json_data_val, ensure_ascii=False) if json_data_val is not None else None
                    val_qd = {'QuestionID': global_qid, 'BusType': bus_type, 'SourceDetailID': src_detail_id,
                              'Context': self._get_safe_from_dict(sr_item, 'Context'),
                              'Give': self._get_safe_from_dict(sr_item, 'Give'),
                              'Notes': self._get_safe_from_dict(sr_item, 'Notes'), 'JsonData': json_str,
                              'Title': self._get_safe_from_dict(sr_item, 'Title'),
                              'IsProductBook': bool(self._get_safe_from_dict(sr_item, 'IsProductBook', 0)),
                              'LinkedKnowledgePointID': linked_kp_db_id}
                    sql_qd = "INSERT INTO QuestionDetails (QuestionID, BusType, SourceDetailID, Context, Give, Notes, JsonData, Title, IsProductBook, LinkedKnowledgePointID) VALUES (%(QuestionID)s, %(BusType)s, %(SourceDetailID)s, %(Context)s, %(Give)s, %(Notes)s, %(JsonData)s, %(Title)s, %(IsProductBook)s, %(LinkedKnowledgePointID)s) ON DUPLICATE KEY UPDATE Context=VALUES(Context), Give=VALUES(Give), Notes=VALUES(Notes), JsonData=VALUES(JsonData), Title=VALUES(Title), IsProductBook=VALUES(IsProductBook), LinkedKnowledgePointID=VALUES(LinkedKnowledgePointID);"
                    try:
                        self.cursor.execute(sql_qd, val_qd); stats['qd']['s'] += 1
                    except mysql.connector.Error as err:
                        stats['qd']['f'] += 1; self.signal_log.emit(
                            f"  å¤„ç†QD (SourceDetailID {src_detail_id})å‡ºé”™: {err.msg}")

            if q_content.get('third_request'):
                sql_rq = "INSERT INTO RelatedQuestions (SourceQuestionID, RelatedQuestionOriginalID, SourceThirdRequestID, RelatedQuestionText, LinkNames, FocalLink, QuestionPage) VALUES (%(SourceQuestionID)s, %(RelatedQuestionOriginalID)s, %(SourceThirdRequestID)s, %(RelatedQuestionText)s, %(LinkNames)s, %(FocalLink)s, %(QuestionPage)s) ON DUPLICATE KEY UPDATE SourceThirdRequestID=VALUES(SourceThirdRequestID), RelatedQuestionText=VALUES(RelatedQuestionText), LinkNames=VALUES(LinkNames), FocalLink=VALUES(FocalLink), QuestionPage=VALUES(QuestionPage);"
                for tr_item in q_content['third_request']:
                    rel_q_orig_id = self._get_safe_from_dict(tr_item, 'QuestionID')
                    if rel_q_orig_id is None: stats['rq']['f'] += 1; self.signal_log.emit(
                        "  è·³è¿‡RQ: RelatedQuestionOriginalIDç¼ºå¤±ã€‚"); continue
                    val_rq = {'SourceQuestionID': global_qid, 'RelatedQuestionOriginalID': rel_q_orig_id,
                              'SourceThirdRequestID': self._get_safe_from_dict(tr_item, 'ID'),
                              'RelatedQuestionText': self._get_safe_from_dict(tr_item, 'QuestionTxt'),
                              'LinkNames': self._get_safe_from_dict(tr_item, 'LinkNames'),
                              'FocalLink': self._get_safe_from_dict(tr_item, 'FocalLink'),
                              'QuestionPage': self._get_safe_from_dict(tr_item, 'QuestionPage')}
                    try:
                        self.cursor.execute(sql_rq, val_rq); stats['rq']['s'] += 1
                    except mysql.connector.Error as err:
                        stats['rq']['f'] += 1; self.signal_log.emit(f"  å¤„ç†RQ (RelatedQID {rel_q_orig_id})å‡ºé”™: {err.msg}")
            self.cnx.commit();
            self.signal_log.emit(f"  å·²æäº¤å…¨å±€QID {global_qid} çš„è¯¦ç»†ä¿¡æ¯ã€‚")
        self.cursor.execute("SET SESSION foreign_key_checks = 1;")
        return stats

    def fetch_books_task(self):
        self.signal_log.emit("æ­£åœ¨ä»æ•°æ®åº“è·å–ä¹¦ç±åˆ—è¡¨...")
        try:
            self.cursor.execute(
                "SELECT b.ID as InternalBookPK, b.BookID as MeaningfulBookID, b.BookTitle, s.SubjectName FROM Books b JOIN Subjects s ON b.SubjectID = s.SubjectID ORDER BY s.SubjectName, b.BookTitle")
            books = self.cursor.fetchall()
            self.signal_populate_book_combo.emit(books or [])
            self.signal_finished.emit("æˆåŠŸè·å–ä¹¦ç±åˆ—è¡¨ã€‚" if books else "æ•°æ®åº“ä¸­æœªæ‰¾åˆ°ä¹¦ç±ã€‚")
        except mysql.connector.Error as err:
            self.signal_log.emit(f"è·å–ä¹¦ç±åˆ—è¡¨å‡ºé”™: {err}")
            self.signal_finished.emit(f"è·å–ä¹¦ç±åˆ—è¡¨å‡ºé”™: {err.msg}")
        except Exception as e:
            self.signal_log.emit(f"è·å–ä¹¦ç±åˆ—è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯: {e}")
            self.signal_finished.emit("è·å–ä¹¦ç±åˆ—è¡¨æ—¶å‘ç”ŸæœªçŸ¥é”™è¯¯ã€‚")


# --- ä¸»GUIåº”ç”¨ ---
class DBImporterApp(QWidget):
    def __init__(self):
        super().__init__()
        self.book_json_path = None
        self.quest_json_path = None
        self.existing_books_data = []
        self.initUI()
        self.worker = None
        self.progress_dialog = None

    def initUI(self):
        self.setWindowTitle('OJLD æ•°æ®å¯¼å…¥å·¥å…·')  # ä¸­æ–‡æ ‡é¢˜
        self.setGeometry(100, 100, 750, 850)  # è°ƒæ•´çª—å£å¤§å°

        main_layout = QVBoxLayout(self)
        tabs = QTabWidget()
        tabs.setFont(QFont("å¾®è½¯é›…é»‘", 10))  # è®¾ç½®Tabå­—ä½“

        # --- Tab 1: æ•°æ®åº“ç»“æ„ç®¡ç† ---
        schema_tab = QWidget()
        schema_layout = QVBoxLayout(schema_tab)
        schema_layout.setAlignment(Qt.AlignTop)
        schema_layout.setSpacing(15)  # å¢åŠ é—´è·

        reset_schema_button = QPushButton('âš ï¸ é‡ç½®å¹¶é‡å»ºæ•°æ®åº“ç»“æ„ (å±é™©æ“ä½œ!)')
        reset_schema_button.setStyleSheet(
            "background-color: #FFEBEE; color: #D32F2F; font-weight: bold; padding: 12px; border-radius: 5px; font-size: 11pt;")
        reset_schema_button.clicked.connect(self.confirm_reset_schema)

        schema_info_label = QLabel("æ­¤æ“ä½œå°†<b>åˆ é™¤æ‰€æœ‰ç°æœ‰æ•°æ®è¡¨</b>å¹¶é‡æ–°åˆ›å»ºæ•°æ®åº“ç»“æ„ã€‚<br>è¯·<b>æåº¦è°¨æ…</b>ä½¿ç”¨ï¼å»ºè®®æ“ä½œå‰å¤‡ä»½æ•°æ®åº“ã€‚")
        schema_info_label.setWordWrap(True)

        schema_layout.addWidget(reset_schema_button)
        schema_layout.addWidget(schema_info_label)
        tabs.addTab(schema_tab, "æ•°æ®åº“ç»“æ„ç®¡ç†")

        # --- Tab 2: å¯¼å…¥ book.json ---
        book_json_tab = QWidget()
        book_json_layout = QVBoxLayout(book_json_tab)
        book_json_layout.setAlignment(Qt.AlignTop)
        book_json_layout.setSpacing(10)

        select_book_json_button = QPushButton("é€‰æ‹© `book.json` æ–‡ä»¶")
        select_book_json_button.setStyleSheet("padding: 8px;")
        select_book_json_button.clicked.connect(self.select_book_json_file)
        self.book_json_label = QLabel("å°šæœªé€‰æ‹© `book.json` æ–‡ä»¶ã€‚")
        self.book_json_label.setStyleSheet("color: #555;")

        upload_book_json_button = QPushButton("ä¸Šä¼ ä¹¦ç±ç»“æ„æ•°æ® (`book.json`)")
        upload_book_json_button.setStyleSheet(
            "background-color: #E8F5E9; color: #2E7D32; font-weight: bold; padding: 10px; border-radius: 5px; font-size: 10pt;")
        upload_book_json_button.clicked.connect(self.upload_book_json_data)

        book_json_layout.addWidget(select_book_json_button)
        book_json_layout.addWidget(self.book_json_label)
        book_json_layout.addSpacing(20)
        book_json_layout.addWidget(upload_book_json_button)
        tabs.addTab(book_json_tab, "å¯¼å…¥ä¹¦ç±ç»“æ„ (book.json)")

        # --- Tab 3: å¯¼å…¥ quest.json ---
        quest_json_tab = QWidget()
        quest_json_layout = QVBoxLayout(quest_json_tab)
        quest_json_layout.setAlignment(Qt.AlignTop)
        quest_json_layout.setSpacing(10)

        select_quest_json_button = QPushButton("é€‰æ‹© `quest.json` æ–‡ä»¶")
        select_quest_json_button.setStyleSheet("padding: 8px;")
        select_quest_json_button.clicked.connect(self.select_quest_json_file)
        self.quest_json_label = QLabel("å°šæœªé€‰æ‹© `quest.json` æ–‡ä»¶ã€‚")
        self.quest_json_label.setStyleSheet("color: #555;")

        book_selection_group = QGroupBox("é€‰æ‹©ç›®æ ‡ä¹¦ç± (ç”¨äºå…³è”é—®é¢˜è¯¦æƒ…)")
        book_selection_group.setFont(QFont("å¾®è½¯é›…é»‘", 10, QFont.Bold))
        book_selection_form_layout = QFormLayout(book_selection_group)
        book_selection_form_layout.setSpacing(10)

        self.refresh_books_button = QPushButton("ğŸ”„ åˆ·æ–°ä¹¦ç±åˆ—è¡¨")
        self.refresh_books_button.setStyleSheet("padding: 6px;")
        self.refresh_books_button.clicked.connect(self.fetch_and_populate_books_combo)
        self.book_combo = QComboBox()
        self.book_combo.addItem("--- è¯·é€‰æ‹©å·²æœ‰ä¹¦ç± ---", None)
        self.book_combo.addItem("+++ åˆ›å»ºæ–°ä¹¦ç± +++", "CREATE_NEW")
        self.book_combo.currentIndexChanged.connect(self.handle_book_selection_change)

        book_selection_form_layout.addRow(self.refresh_books_button)
        book_selection_form_layout.addRow(QLabel("å…³è”é—®é¢˜åˆ°:"), self.book_combo)

        self.new_book_group = QGroupBox("æ–°ä¹¦ç±è¯¦æƒ… (è‹¥é€‰æ‹©'åˆ›å»ºæ–°ä¹¦ç±')")
        self.new_book_group.setFont(QFont("å¾®è½¯é›…é»‘", 10, QFont.Bold))
        new_book_form = QFormLayout(self.new_book_group)
        new_book_form.setSpacing(10)
        self.new_book_title_edit = QLineEdit()
        self.new_book_meaningful_id_edit = QLineEdit()
        self.new_book_subject_combo = QComboBox()
        new_book_form.addRow("æ–°ä¹¦ç±æ ‡é¢˜:", self.new_book_title_edit)
        new_book_form.addRow("æ–°ä¹¦ç±ä¸šåŠ¡ID (å”¯ä¸€æ•´æ•°):", self.new_book_meaningful_id_edit)
        new_book_form.addRow("æ–°ä¹¦ç±æ‰€å±ç§‘ç›®:", self.new_book_subject_combo)
        self.new_book_group.setVisible(False)

        upload_quest_json_button = QPushButton("ä¸Šä¼ é—®é¢˜è¯¦æƒ…æ•°æ® (`quest.json`)")
        upload_quest_json_button.setStyleSheet(
            "background-color: #E3F2FD; color: #1565C0; font-weight: bold; padding: 10px; border-radius: 5px; font-size: 10pt;")
        upload_quest_json_button.clicked.connect(self.upload_quest_json_data)

        quest_json_layout.addWidget(select_quest_json_button)
        quest_json_layout.addWidget(self.quest_json_label)
        quest_json_layout.addWidget(book_selection_group)
        quest_json_layout.addWidget(self.new_book_group)
        quest_json_layout.addSpacing(20)
        quest_json_layout.addWidget(upload_quest_json_button)
        tabs.addTab(quest_json_tab, "å¯¼å…¥é—®é¢˜è¯¦æƒ… (quest.json)")

        # --- æ—¥å¿—åŒºåŸŸ ---
        log_label = QLabel("æ“ä½œæ—¥å¿—:")
        log_label.setFont(QFont("å¾®è½¯é›…é»‘", 10, QFont.Bold))
        self.log_area = QTextEdit()
        self.log_area.setReadOnly(True)
        self.log_area.setFont(QFont("Consolas", 9))  # ä½¿ç”¨Consolasæˆ–ç±»ä¼¼çš„ç­‰å®½å­—ä½“
        self.log_area.setLineWrapMode(QTextEdit.WidgetWidth)  # è‡ªåŠ¨æ¢è¡Œ
        self.log_area.setStyleSheet("background-color: #f5f5f5; border: 1px solid #ccc; padding: 5px;")

        main_layout.addWidget(tabs)
        main_layout.addWidget(log_label)
        main_layout.addWidget(self.log_area, 1)

        self.setLayout(main_layout)
        self.log_message("åº”ç”¨ç¨‹åºå·²å¯åŠ¨ã€‚å¦‚æœéœ€è¦ï¼Œè¯·åœ¨è„šæœ¬ä¸­é…ç½®æ•°æ®åº“å¯†ç ã€‚")
        self.fetch_and_populate_books_combo()
        self.populate_subjects_combo()

    def log_message(self, message):
        self.log_area.append(message)
        self.log_area.verticalScrollBar().setValue(self.log_area.verticalScrollBar().maximum())

    def show_progress_dialog(self, title, max_val=0):  # è®¾ç½®ä¸­æ–‡æ ‡é¢˜
        self.progress_dialog = QProgressDialog(title, "å–æ¶ˆ", 0, max_val, self)
        self.progress_dialog.setWindowTitle("å¤„ç†ä¸­")  # å¯¹è¯æ¡†æ ‡é¢˜
        self.progress_dialog.setWindowModality(Qt.WindowModal)
        self.progress_dialog.setAutoClose(True)
        self.progress_dialog.setAutoReset(True)
        self.progress_dialog.setValue(0)
        self.progress_dialog.canceled.connect(self.cancel_worker)
        self.progress_dialog.show()

    def update_progress_max(self, max_val):
        if self.progress_dialog: self.progress_dialog.setMaximum(max_val)

    def update_progress_value(self, value):
        if self.progress_dialog:
            self.progress_dialog.setValue(value)
            # if value >= self.progress_dialog.maximum(): self.progress_dialog.reset() # AutoReset handles this

    def cancel_worker(self):
        if self.worker and self.worker.isRunning():
            self.log_message("è¯·æ±‚å–æ¶ˆä»»åŠ¡...")  # ä¸­æ–‡
            self.worker.requestInterruption()

    def task_finished(self, message):
        self.log_message(f"ä»»åŠ¡å®Œæˆ: {message}")  # ä¸­æ–‡
        if self.progress_dialog: self.progress_dialog.reset()
        QMessageBox.information(self, "ä»»åŠ¡å®Œæˆ", message)  # ä¸­æ–‡æ ‡é¢˜å’Œå†…å®¹
        if hasattr(self.worker, 'task_type') and (
                self.worker.task_type == "import_quest_json" or self.worker.task_type == "reset_schema"):
            self.fetch_and_populate_books_combo()

    def confirm_reset_schema(self):
        reply = QMessageBox.warning(self, 'ç¡®è®¤é‡ç½®æ•°æ®åº“ç»“æ„',  # ä¸­æ–‡æ ‡é¢˜
                                    "æ‚¨ç¡®å®šè¦åˆ é™¤æ‰€æœ‰æ•°æ®è¡¨å¹¶é‡æ–°åˆ›å»ºæ•°æ®åº“ç»“æ„å—ï¼Ÿ\n"
                                    "æ­¤æ“ä½œ<b>ä¸å¯é€†</b>ï¼Œå°†åˆ é™¤æ‰€æœ‰æ•°æ®ï¼è¯·è°¨æ…æ“ä½œï¼",  # ä¸­æ–‡å†…å®¹
                                    QMessageBox.Yes | QMessageBox.No, QMessageBox.No)
        if reply == QMessageBox.Yes:
            self.log_message("ç”¨æˆ·å·²ç¡®è®¤é‡ç½®æ•°æ®åº“ç»“æ„ã€‚")  # ä¸­æ–‡
            self.worker = WorkerThread(task_type="reset_schema")
            self.worker.signal_log.connect(self.log_message)
            self.worker.signal_finished.connect(self.task_finished)
            self.worker.start()
            self.show_progress_dialog("æ­£åœ¨é‡ç½®æ•°æ®åº“ç»“æ„...")  # ä¸­æ–‡
        else:
            self.log_message("ç”¨æˆ·å–æ¶ˆäº†æ•°æ®åº“ç»“æ„é‡ç½®æ“ä½œã€‚")  # ä¸­æ–‡

    def select_book_json_file(self):
        filePath, _ = QFileDialog.getOpenFileName(self, "é€‰æ‹© `book.json` æ–‡ä»¶", "", "JSON æ–‡ä»¶ (*.json)")  # ä¸­æ–‡
        if filePath:
            self.book_json_path = filePath
            self.book_json_label.setText(f"å·²é€‰æ‹©: {os.path.basename(filePath)}")  # ä¸­æ–‡
            self.log_message(f"`book.json` å·²é€‰æ‹©: {filePath}")  # ä¸­æ–‡

    def upload_book_json_data(self):
        if not self.book_json_path:
            QMessageBox.warning(self, "æœªé€‰æ‹©æ–‡ä»¶", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ª `book.json` æ–‡ä»¶ã€‚")  # ä¸­æ–‡
            return
        self.log_message(f"å¼€å§‹ä¸Šä¼  `book.json`: {self.book_json_path}")  # ä¸­æ–‡
        self.worker = WorkerThread(task_type="import_book_json", json_file_path=self.book_json_path)
        # ... (ä¿¡å·è¿æ¥ä¿æŒä¸å˜)
        self.worker.signal_log.connect(self.log_message)
        self.worker.signal_finished.connect(self.task_finished)
        self.worker.signal_progress_max.connect(self.update_progress_max)
        self.worker.signal_progress_value.connect(self.update_progress_value)
        self.worker.start()
        self.show_progress_dialog(f"æ­£åœ¨å¯¼å…¥ {os.path.basename(self.book_json_path)}...")  # ä¸­æ–‡

    def select_quest_json_file(self):
        filePath, _ = QFileDialog.getOpenFileName(self, "é€‰æ‹© `quest.json` æ–‡ä»¶", "", "JSON æ–‡ä»¶ (*.json)")  # ä¸­æ–‡
        if filePath:
            self.quest_json_path = filePath
            self.quest_json_label.setText(f"å·²é€‰æ‹©: {os.path.basename(filePath)}")  # ä¸­æ–‡
            self.log_message(f"`quest.json` å·²é€‰æ‹©: {filePath}")  # ä¸­æ–‡

    def fetch_and_populate_books_combo(self):
        self.log_message("æ­£åœ¨è·å–ä¹¦ç±åˆ—è¡¨ä»¥å¡«å……ä¸‹æ‹‰æ¡†...")  # ä¸­æ–‡
        self.worker = WorkerThread(task_type="fetch_books")
        # ... (ä¿¡å·è¿æ¥ä¿æŒä¸å˜)
        self.worker.signal_log.connect(self.log_message)
        self.worker.signal_finished.connect(self.task_finished)
        self.worker.signal_populate_book_combo.connect(self.populate_book_combo_actual)
        self.worker.start()

    def populate_book_combo_actual(self, books_list_from_db):
        self.book_combo.clear()
        self.book_combo.addItem("--- è¯·é€‰æ‹©å·²æœ‰ä¹¦ç± ---", None)  # ä¸­æ–‡
        self.book_combo.addItem("+++ åˆ›å»ºæ–°ä¹¦ç± +++", "CREATE_NEW")  # ä¸­æ–‡
        self.existing_books_data = []
        if books_list_from_db:
            for book_row in books_list_from_db:
                display_text = f"{book_row['BookTitle']} (ç§‘ç›®: {book_row['SubjectName']}, ä¸šåŠ¡ID: {book_row['MeaningfulBookID']})"  # ä¸­æ–‡
                self.book_combo.addItem(display_text, book_row['MeaningfulBookID'])
                self.existing_books_data.append({
                    'text': display_text, 'meaningful_id': book_row['MeaningfulBookID'],
                    'internal_pk': book_row['InternalBookPK']})
        self.log_message(f"ä¹¦ç±ä¸‹æ‹‰æ¡†å·²å¡«å…… {len(books_list_from_db)} æœ¬ä¹¦ç±ã€‚")  # ä¸­æ–‡

    def populate_subjects_combo(self):
        self.new_book_subject_combo.clear()
        cnx = None;
        cursor = None
        try:
            cnx = mysql.connector.connect(**DB_CONFIG)
            cursor = cnx.cursor(dictionary=True)
            cursor.execute("SELECT SubjectID, SubjectName FROM Subjects ORDER BY SubjectName")
            subjects = cursor.fetchall()
            if subjects:
                for subject in subjects:
                    self.new_book_subject_combo.addItem(subject['SubjectName'], subject['SubjectID'])
            else:
                self.new_book_subject_combo.addItem("æœªæ‰¾åˆ°ç§‘ç›®", None)  # ä¸­æ–‡
        except mysql.connector.Error as err:
            self.log_message(f"è·å–æ–°ä¹¦ç§‘ç›®åˆ—è¡¨å‡ºé”™: {err}")  # ä¸­æ–‡
            self.new_book_subject_combo.addItem("åŠ è½½ç§‘ç›®å‡ºé”™", None)  # ä¸­æ–‡
        finally:
            if cursor: cursor.close()
            if cnx and cnx.is_connected(): cnx.close()

    def handle_book_selection_change(self, index):
        selected_data = self.book_combo.itemData(index)
        if selected_data == "CREATE_NEW":
            self.new_book_group.setVisible(True)
        else:
            self.new_book_group.setVisible(False)

    def upload_quest_json_data(self):
        if not self.quest_json_path:
            QMessageBox.warning(self, "æœªé€‰æ‹©æ–‡ä»¶", "è¯·å…ˆé€‰æ‹©ä¸€ä¸ª `quest.json` æ–‡ä»¶ã€‚")  # ä¸­æ–‡
            return
        selected_book_combo_data = self.book_combo.currentData()
        target_book_meaningful_id = None;
        is_new_book = False;
        book_title_for_log = ""
        new_book_internal_pk = None
        if selected_book_combo_data == "CREATE_NEW":
            is_new_book = True
            book_title_for_log = self.new_book_title_edit.text().strip()
            meaningful_id_str = self.new_book_meaningful_id_edit.text().strip()
            selected_subject_id_for_new_book = self.new_book_subject_combo.currentData()
            if not book_title_for_log: QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "æ–°ä¹¦ç±æ ‡é¢˜ä¸èƒ½ä¸ºç©ºã€‚"); return  # ä¸­æ–‡
            if not meaningful_id_str: QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "æ–°ä¹¦ç±ä¸šåŠ¡IDä¸èƒ½ä¸ºç©ºã€‚"); return  # ä¸­æ–‡
            try:
                target_book_meaningful_id = int(meaningful_id_str)
            except ValueError:
                QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "æ–°ä¹¦ç±ä¸šåŠ¡IDå¿…é¡»æ˜¯æ•´æ•°ã€‚"); return  # ä¸­æ–‡
            if selected_subject_id_for_new_book is None: QMessageBox.warning(self, "è¾“å…¥é”™è¯¯", "è¯·ä¸ºæ–°ä¹¦ç±é€‰æ‹©ç§‘ç›®ã€‚"); return  # ä¸­æ–‡

            cnx_check = None;
            cursor_check = None
            try:  # ... (åˆ›å»ºæ–°ä¹¦çš„é€»è¾‘ä¿æŒä¸å˜)
                cnx_check = mysql.connector.connect(**DB_CONFIG)
                cursor_check = cnx_check.cursor()
                cursor_check.execute("SELECT ID FROM Books WHERE BookID = %s", (target_book_meaningful_id,))
                if cursor_check.fetchone(): QMessageBox.warning(self, "è¾“å…¥é”™è¯¯",
                                                                f"ä¸šåŠ¡IDä¸º {target_book_meaningful_id} çš„ä¹¦ç±å·²å­˜åœ¨ã€‚"); return
                sql_ib = "INSERT INTO Books (BookID, BookTitle, SubjectID, SourceJsonFileName) VALUES (%s, %s, %s, %s)"
                cursor_check.execute(sql_ib, (
                target_book_meaningful_id, book_title_for_log, selected_subject_id_for_new_book,
                os.path.basename(self.quest_json_path)))
                new_book_internal_pk = cursor_check.lastrowid;
                cnx_check.commit()
                self.log_message(
                    f"æ–°ä¹¦ç± '{book_title_for_log}' å·²åˆ›å»º (ä¸šåŠ¡ID: {target_book_meaningful_id}, å†…éƒ¨ä¸»é”®: {new_book_internal_pk})ã€‚")
            except mysql.connector.Error as err:
                QMessageBox.critical(self, "æ•°æ®åº“é”™è¯¯", f"åˆ›å»ºæ–°ä¹¦ç±æ—¶å‡ºé”™: {err}"); return
            finally:  # ... (å…³é—­è¿æ¥)
                if cursor_check: cursor_check.close()
                if cnx_check and cnx_check.is_connected(): cnx_check.close()
            if new_book_internal_pk is None: QMessageBox.critical(self, "é”™è¯¯", "æœªèƒ½è·å–æ–°ä¹¦ç±çš„å†…éƒ¨ä¸»é”®ã€‚"); return

        elif selected_book_combo_data is not None:  # ... (é€‰æ‹©å·²æœ‰ä¹¦ç±çš„é€»è¾‘ä¿æŒä¸å˜)
            target_book_meaningful_id = selected_book_combo_data
            selected_book_internal_pk_for_update = None
            for book_entry in self.existing_books_data:
                if book_entry['meaningful_id'] == target_book_meaningful_id:
                    selected_book_internal_pk_for_update = book_entry['internal_pk']
                    book_title_for_log = self.book_combo.currentText().split(' (ç§‘ç›®:')[0]
                    break
            if selected_book_internal_pk_for_update is None: QMessageBox.critical(self, "é”™è¯¯",
                                                                                  "æ— æ³•æ‰¾åˆ°æ‰€é€‰å·²æœ‰ä¹¦ç±çš„å†…éƒ¨ä¸»é”®ã€‚"); return
            cnx_update = None;
            cursor_update = None
            try:
                cnx_update = mysql.connector.connect(**DB_CONFIG)
                cursor_update = cnx_update.cursor()
                cursor_update.execute("UPDATE Books SET SourceJsonFileName = %s WHERE ID = %s",
                                      (os.path.basename(self.quest_json_path), selected_book_internal_pk_for_update))
                cnx_update.commit()
                self.log_message(
                    f"å·²æ›´æ–°ä¹¦ç± '{book_title_for_log}' çš„SourceJsonFileNameä¸º '{os.path.basename(self.quest_json_path)}'ã€‚")
            except mysql.connector.Error as err:
                QMessageBox.warning(self, "æ•°æ®åº“é”™è¯¯", f"æ— æ³•æ›´æ–°ä¹¦ç±çš„SourceJsonFileName: {err}")
            finally:  # ... (å…³é—­è¿æ¥)
                if cursor_update: cursor_update.close()
                if cnx_update and cnx_update.is_connected(): cnx_update.close()
        else:
            QMessageBox.warning(self, "æœªé€‰æ‹©ä¹¦ç±", "è¯·é€‰æ‹©ä¸€ä¸ªå·²æœ‰ä¹¦ç±æˆ–é€‰æ‹©åˆ›å»ºæ–°ä¹¦ç±ã€‚"); return  # ä¸­æ–‡

        if target_book_meaningful_id is None: QMessageBox.critical(self, "é”™è¯¯", "æ— æ³•ç¡®å®šç›®æ ‡ä¹¦ç±IDã€‚"); return  # ä¸­æ–‡
        self.log_message(
            f"å¼€å§‹ä¸Šä¼  `quest.json`: {self.quest_json_path}ï¼Œç›®æ ‡ä¹¦ç±: '{book_title_for_log}' (ä¸šåŠ¡ID: {target_book_meaningful_id})")  # ä¸­æ–‡
        self.worker = WorkerThread(task_type="import_quest_json", json_file_path=self.quest_json_path,
                                   target_book_meaningful_id=target_book_meaningful_id, is_new_book=is_new_book,
                                   book_title_for_log=book_title_for_log)
        # ... (ä¿¡å·è¿æ¥ä¿æŒä¸å˜)
        self.worker.signal_log.connect(self.log_message)
        self.worker.signal_finished.connect(self.task_finished)
        self.worker.signal_progress_max.connect(self.update_progress_max)
        self.worker.signal_progress_value.connect(self.update_progress_value)
        self.worker.start()
        self.show_progress_dialog(f"æ­£åœ¨ä¸º '{book_title_for_log}' å¯¼å…¥ {os.path.basename(self.quest_json_path)}...")  # ä¸­æ–‡


if __name__ == '__main__':
    app = QApplication(sys.argv)
    ex = DBImporterApp()
    ex.show()
    sys.exit(app.exec_())